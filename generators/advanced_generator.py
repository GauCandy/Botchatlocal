"""
Advanced Training Data Generator v·ªõi nhi·ªÅu t√≠nh nƒÉng
- H·ªó tr·ª£ custom scenarios
- Quality filtering
- Progress tracking
- Multiple languages
- Error handling v√† retry logic
"""

import json
import asyncio
import aiohttp
import random
from typing import List, Dict, Optional
from datetime import datetime
from pathlib import Path
import logging
from tqdm.asyncio import tqdm
import config

# Setup logging
logging.basicConfig(
    level=logging.INFO if config.VERBOSE else logging.WARNING,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(config.LOG_FILE) if config.SAVE_LOGS else logging.NullHandler(),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class AdvancedTrainingDataGenerator:
    """Advanced generator v·ªõi nhi·ªÅu t√≠nh nƒÉng n√¢ng cao"""

    def __init__(self):
        self.api_key = config.OPENAI_API_KEY or config.ANTHROPIC_API_KEY
        self.api_type = config.API_TYPE
        self.model = config.MODEL_NAME
        self.generated_data = []
        self.failed_generations = []
        self.stats = {
            "total_attempts": 0,
            "successful": 0,
            "failed": 0,
            "filtered_out": 0
        }

    async def generate_with_retry(self, scenario: Dict, session: aiohttp.ClientSession, max_retries: int = 3) -> Optional[Dict]:
        """Sinh conversation v·ªõi retry logic"""

        for attempt in range(max_retries):
            try:
                self.stats["total_attempts"] += 1

                prompt = self._create_advanced_prompt(scenario)

                if self.api_type == "openai":
                    response = await self._call_openai(prompt, session)
                elif self.api_type == "anthropic":
                    response = await self._call_anthropic(prompt, session)
                else:
                    logger.error(f"Unsupported API type: {self.api_type}")
                    return None

                conversation = self._parse_and_validate(response, scenario)

                if conversation and self._quality_check(conversation):
                    self.stats["successful"] += 1
                    return conversation
                else:
                    self.stats["filtered_out"] += 1
                    logger.warning(f"Conversation filtered out: quality check failed")

            except Exception as e:
                logger.error(f"Attempt {attempt + 1} failed: {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(config.RETRY_DELAY * (attempt + 1))
                else:
                    self.stats["failed"] += 1
                    self.failed_generations.append({
                        "scenario": scenario,
                        "error": str(e),
                        "timestamp": datetime.now().isoformat()
                    })

        return None

    def _create_advanced_prompt(self, scenario: Dict) -> str:
        """T·∫°o prompt n√¢ng cao v·ªõi nhi·ªÅu y√™u c·∫ßu chi ti·∫øt"""

        language = config.PRIMARY_LANGUAGE
        turns = scenario.get('turns', config.DEFAULT_TURNS)

        prompt = f"""T·∫°o m·ªôt cu·ªôc h·ªôi tho·∫°i ch·∫•t l∆∞·ª£ng cao gi·ªØa User v√† AI Assistant:

TH√îNG TIN:
- Ch·ªß ƒë·ªÅ: {scenario['topic']}
- Ng·ªØ c·∫£nh: {scenario['context']}
- M·ª•c ti√™u: {scenario['goal']}
- S·ªë l∆∞·ª£t: {turns} turns
- Ng√¥n ng·ªØ: {"Ti·∫øng Vi·ªát" if language == "vi" else "English"}

Y√äU C·∫¶U CH·∫§T L∆Ø·ª¢NG:
1. H·ªôi tho·∫°i ph·∫£i T·ª∞ NHI√äN nh∆∞ ng∆∞·ªùi th·∫≠t n√≥i chuy·ªán
2. User c√≥ th·ªÉ:
   - H·ªèi c√¢u kh√¥ng r√µ r√†ng, thi·∫øu th√¥ng tin
   - H·ªèi follow-up questions
   - Thay ƒë·ªïi ch·ªß ƒë·ªÅ nh·∫π
   - D√πng ng√¥n ng·ªØ th√¥ng t·ª•c, informal
3. AI Assistant ph·∫£i:
   - Tr·∫£ l·ªùi ch√≠nh x√°c, h·ªØu √≠ch
   - Y√™u c·∫ßu clarification n·∫øu c√¢u h·ªèi kh√¥ng r√µ
   - ƒê∆∞a ra v√≠ d·ª• c·ª• th·ªÉ khi c·∫ßn
   - Gi·∫£i th√≠ch ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu
   - Th·ªÉ hi·ªán empathy v√† friendliness
4. ƒê·ªô d√†i response: {config.MIN_RESPONSE_LENGTH}-{config.MAX_RESPONSE_LENGTH} k√Ω t·ª±

C·∫§U TR√öC C√ÇU H·ªéI ƒêA D·∫†NG:
- Informational: "Cho t√¥i bi·∫øt v·ªÅ..."
- How-to: "L√†m th·∫ø n√†o ƒë·ªÉ..."
- Comparison: "So s√°nh A v√† B..."
- Troubleshooting: "T√¥i g·∫∑p v·∫•n ƒë·ªÅ..."
- Opinion/Advice: "B·∫°n nghƒ© g√¨ v·ªÅ..."

OUTPUT FORMAT (JSON):
{{
    "conversation": [
        {{"role": "user", "content": "..."}},
        {{"role": "assistant", "content": "..."}},
        ...
    ],
    "metadata": {{
        "topic": "{scenario['topic']}",
        "category": "{scenario.get('category', 'general')}",
        "difficulty": "easy|medium|hard",
        "language": "{language}",
        "quality_score": 8-10
    }}
}}

CH·ªà tr·∫£ v·ªÅ JSON, KH√îNG th√™m text kh√°c."""

        return prompt

    async def _call_openai(self, prompt: str, session: aiohttp.ClientSession) -> str:
        """Call OpenAI API v·ªõi error handling"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": "B·∫°n l√† chuy√™n gia t·∫°o d·ªØ li·ªáu training cho AI. T·∫°o conversations t·ª± nhi√™n, ch·∫•t l∆∞·ª£ng cao, ƒëa d·∫°ng. Lu√¥n tr·∫£ v·ªÅ JSON h·ª£p l·ªá."
                },
                {"role": "user", "content": prompt}
            ],
            "temperature": config.TEMPERATURE,
            "response_format": {"type": "json_object"}
        }

        async with session.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=aiohttp.ClientTimeout(total=config.REQUEST_TIMEOUT)
        ) as response:
            if response.status != 200:
                error_text = await response.text()
                raise Exception(f"OpenAI API error {response.status}: {error_text}")

            result = await response.json()
            return result['choices'][0]['message']['content']

    async def _call_anthropic(self, prompt: str, session: aiohttp.ClientSession) -> str:
        """Call Anthropic API v·ªõi error handling"""
        headers = {
            "x-api-key": self.api_key,
            "anthropic-version": "2023-06-01",
            "content-type": "application/json"
        }

        data = {
            "model": self.model,
            "max_tokens": 4096,
            "messages": [{"role": "user", "content": prompt}],
            "system": "B·∫°n l√† chuy√™n gia t·∫°o d·ªØ li·ªáu training cho AI. T·∫°o conversations t·ª± nhi√™n, ch·∫•t l∆∞·ª£ng cao, ƒëa d·∫°ng. Lu√¥n tr·∫£ v·ªÅ JSON h·ª£p l·ªá.",
            "temperature": config.TEMPERATURE
        }

        async with session.post(
            "https://api.anthropic.com/v1/messages",
            headers=headers,
            json=data,
            timeout=aiohttp.ClientTimeout(total=config.REQUEST_TIMEOUT)
        ) as response:
            if response.status != 200:
                error_text = await response.text()
                raise Exception(f"Anthropic API error {response.status}: {error_text}")

            result = await response.json()
            return result['content'][0]['text']

    def _parse_and_validate(self, response: str, scenario: Dict) -> Optional[Dict]:
        """Parse v√† validate response"""
        try:
            # Parse JSON
            data = json.loads(response)

            # Validate structure
            if "conversation" not in data or not isinstance(data["conversation"], list):
                logger.warning("Invalid conversation structure")
                return None

            if len(data["conversation"]) < 2:
                logger.warning("Conversation too short")
                return None

            # Create formatted conversation
            conversation_data = {
                "id": f"conv_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(1000, 9999)}",
                "timestamp": datetime.now().isoformat(),
                "scenario": scenario,
                "conversation": data["conversation"],
                "metadata": data.get("metadata", {}),
                "source": f"{self.api_type}_{self.model}"
            }

            return conversation_data

        except json.JSONDecodeError as e:
            logger.error(f"JSON parse error: {e}")
            return None

    def _quality_check(self, conversation: Dict) -> bool:
        """Ki·ªÉm tra ch·∫•t l∆∞·ª£ng conversation"""

        if not config.ENABLE_QUALITY_FILTER:
            return True

        try:
            conv = conversation["conversation"]

            # Check minimum turns
            if len(conv) < 4:
                return False

            # Check response lengths
            for turn in conv:
                content_len = len(turn["content"])
                if content_len < config.MIN_RESPONSE_LENGTH:
                    logger.debug(f"Response too short: {content_len} chars")
                    return False
                if content_len > config.MAX_RESPONSE_LENGTH:
                    logger.debug(f"Response too long: {content_len} chars")
                    return False

            # Check alternating roles
            for i in range(len(conv) - 1):
                if conv[i]["role"] == conv[i+1]["role"]:
                    logger.debug("Roles not alternating properly")
                    return False

            return True

        except Exception as e:
            logger.error(f"Quality check error: {e}")
            return False

    async def generate_batch_with_progress(self, scenarios: List[Dict]) -> List[Dict]:
        """Sinh batch v·ªõi progress bar"""

        conversations = []

        async with aiohttp.ClientSession() as session:
            # Create tasks with progress bar
            tasks = []
            for scenario in scenarios:
                task = self.generate_with_retry(scenario, session, config.MAX_RETRIES)
                tasks.append(task)

            # Run with progress bar
            results = []
            for coro in tqdm.as_completed(tasks, total=len(tasks), desc="Generating"):
                result = await coro
                if result:
                    results.append(result)
                    self.generated_data.append(result)

        return results

    def save_all_formats(self, base_filename: str):
        """L∆∞u t·∫•t c·∫£ formats ƒë∆∞·ª£c config"""

        output_dir = Path(config.OUTPUT_DIR)
        output_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        if config.EXPORT_FORMATS.get("json", False):
            self._save_json(output_dir / f"{base_filename}_{timestamp}.json")

        if config.EXPORT_FORMATS.get("jsonl", False):
            self._save_jsonl(output_dir / f"{base_filename}_{timestamp}.jsonl")

        if config.EXPORT_FORMATS.get("csv", False):
            self._save_csv(output_dir / f"{base_filename}_{timestamp}.csv")

        if config.EXPORT_FORMATS.get("openai", False):
            self._save_openai_format(output_dir / f"openai_{base_filename}_{timestamp}.jsonl")

    def _save_json(self, filepath: Path):
        """Save to JSON"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.generated_data, f, ensure_ascii=False, indent=2)
        logger.info(f"‚úì Saved {len(self.generated_data)} conversations to {filepath}")

    def _save_jsonl(self, filepath: Path):
        """Save to JSONL"""
        with open(filepath, 'w', encoding='utf-8') as f:
            for item in self.generated_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        logger.info(f"‚úì Saved {len(self.generated_data)} conversations to {filepath}")

    def _save_csv(self, filepath: Path):
        """Save to CSV"""
        import csv

        rows = []
        for conv in self.generated_data:
            for i, turn in enumerate(conv['conversation']):
                rows.append({
                    'conversation_id': conv['id'],
                    'turn': i,
                    'role': turn['role'],
                    'content': turn['content'],
                    'topic': conv['scenario']['topic'],
                    'timestamp': conv['timestamp']
                })

        if rows:
            with open(filepath, 'w', encoding='utf-8', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=rows[0].keys())
                writer.writeheader()
                writer.writerows(rows)
            logger.info(f"‚úì Saved {len(rows)} turns to {filepath}")

    def _save_openai_format(self, filepath: Path):
        """Save in OpenAI fine-tuning format"""
        with open(filepath, 'w', encoding='utf-8') as f:
            for conv in self.generated_data:
                training_example = {"messages": conv['conversation']}
                f.write(json.dumps(training_example, ensure_ascii=False) + '\n')
        logger.info(f"‚úì Saved {len(self.generated_data)} conversations to {filepath} (OpenAI format)")

    def print_statistics(self):
        """In th·ªëng k√™ chi ti·∫øt"""
        print("\n" + "=" * 70)
        print("TH·ªêNG K√ä CHI TI·∫æT")
        print("=" * 70)

        print(f"\nüìä Generation Stats:")
        print(f"  ‚Ä¢ T·ªïng attempts: {self.stats['total_attempts']}")
        print(f"  ‚Ä¢ Th√†nh c√¥ng: {self.stats['successful']} ‚úì")
        print(f"  ‚Ä¢ Th·∫•t b·∫°i: {self.stats['failed']} ‚úó")
        print(f"  ‚Ä¢ Filtered out: {self.stats['filtered_out']} ‚ö†")

        if self.stats['total_attempts'] > 0:
            success_rate = (self.stats['successful'] / self.stats['total_attempts']) * 100
            print(f"  ‚Ä¢ Success rate: {success_rate:.1f}%")

        if self.generated_data:
            total_turns = sum(len(conv['conversation']) for conv in self.generated_data)
            avg_turns = total_turns / len(self.generated_data)

            print(f"\nüí¨ Conversation Stats:")
            print(f"  ‚Ä¢ T·ªïng conversations: {len(self.generated_data)}")
            print(f"  ‚Ä¢ T·ªïng turns: {total_turns}")
            print(f"  ‚Ä¢ Trung b√¨nh turns/conv: {avg_turns:.1f}")

            # Topics distribution
            topics = {}
            for conv in self.generated_data:
                topic = conv['scenario']['topic']
                topics[topic] = topics.get(topic, 0) + 1

            print(f"\nüìö Top Topics:")
            for topic, count in sorted(topics.items(), key=lambda x: x[1], reverse=True)[:10]:
                print(f"  ‚Ä¢ {topic}: {count}")

        if self.failed_generations:
            print(f"\n‚ö† Failed Generations: {len(self.failed_generations)}")
            print("  Check logs for details")

        print("\n" + "=" * 70)


def load_scenarios() -> List[Dict]:
    """Load scenarios t·ª´ config ho·∫∑c default"""

    from training_data_generator import VIETNAMESE_SCENARIOS

    if config.CUSTOM_SCENARIOS:
        logger.info(f"Using {len(config.CUSTOM_SCENARIOS)} custom scenarios")
        return config.CUSTOM_SCENARIOS

    # Filter by enabled categories
    filtered_scenarios = []
    category_map = {
        "L·∫≠p tr√¨nh": "technology",
        "Kh·∫Øc ph·ª•c l·ªói": "technology",
        "Machine Learning": "technology",
        "Web Development": "technology",
        "Database": "technology",
        "N·∫•u ƒÉn": "food",
        "T·∫≠p th·ªÉ d·ª•c": "lifestyle",
        "Du l·ªãch": "travel",
        "ChƒÉm s√≥c s·ª©c kh·ªèe": "health",
        "Qu·∫£n l√Ω t√†i ch√≠nh": "finance",
        "H·ªçc ti·∫øng Anh": "education",
        "To√°n h·ªçc": "education",
        "Kh·ªüi nghi·ªáp": "business",
        "Marketing": "business",
    }

    for scenario in VIETNAMESE_SCENARIOS:
        # Determine category
        category = "general"
        for keyword, cat in category_map.items():
            if keyword.lower() in scenario['topic'].lower():
                category = cat
                break

        scenario['category'] = category

        # Check if category is enabled
        if config.ENABLED_CATEGORIES.get(category, True):
            filtered_scenarios.append(scenario)

    # Limit to configured number
    if len(filtered_scenarios) > config.NUM_CONVERSATIONS:
        filtered_scenarios = random.sample(filtered_scenarios, config.NUM_CONVERSATIONS)

    logger.info(f"Using {len(filtered_scenarios)} scenarios")
    return filtered_scenarios


async def main():
    """Main function"""
    print("=" * 70)
    print("ü§ñ ADVANCED AI TRAINING DATA GENERATOR")
    print("=" * 70)
    print()

    # Validate API key
    if not (config.OPENAI_API_KEY or config.ANTHROPIC_API_KEY):
        print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y API key!")
        print("\nVui l√≤ng:")
        print("1. Set environment variable:")
        print("   export OPENAI_API_KEY='your-key'")
        print("   ho·∫∑c")
        print("   export ANTHROPIC_API_KEY='your-key'")
        print("\n2. Ho·∫∑c s·ª≠a trong file config.py")
        return

    # Show config
    print(f"‚öôÔ∏è  Configuration:")
    print(f"  ‚Ä¢ API: {config.API_TYPE}")
    print(f"  ‚Ä¢ Model: {config.MODEL_NAME}")
    print(f"  ‚Ä¢ Conversations: {config.NUM_CONVERSATIONS}")
    print(f"  ‚Ä¢ Batch size: {config.BATCH_SIZE}")
    print(f"  ‚Ä¢ Temperature: {config.TEMPERATURE}")
    print()

    # Initialize generator
    generator = AdvancedTrainingDataGenerator()

    # Load scenarios
    scenarios = load_scenarios()
    print(f"üìã Loaded {len(scenarios)} scenarios")
    print()

    # Generate data
    print("üöÄ B·∫Øt ƒë·∫ßu sinh d·ªØ li·ªáu...")
    print("(Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t)\n")

    await generator.generate_batch_with_progress(scenarios)

    # Save results
    print("\nüíæ ƒêang l∆∞u d·ªØ li·ªáu...")
    generator.save_all_formats("conversations")

    # Print statistics
    generator.print_statistics()

    # Save failed generations for debugging
    if generator.failed_generations:
        failed_path = Path(config.OUTPUT_DIR) / "failed_generations.json"
        with open(failed_path, 'w', encoding='utf-8') as f:
            json.dump(generator.failed_generations, f, ensure_ascii=False, indent=2)
        print(f"\n‚ö†  Saved failed generations to {failed_path}")

    print("\n‚úÖ HO√ÄN TH√ÄNH!")
    print(f"üìÅ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u trong: {config.OUTPUT_DIR}/")
    print("\nB·∫°n c√≥ th·ªÉ d√πng c√°c file n√†y ƒë·ªÉ train chatbot! üéâ\n")


if __name__ == "__main__":
    asyncio.run(main())
